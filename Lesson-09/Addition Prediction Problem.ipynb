{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbrom/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, TimeDistributed, Dense, RepeatVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Generate Sum Pairs **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate lists of random integers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "    X, y = [], []\n",
    "    for i in range(n_examples):\n",
    "        in_pattern = [random.randint(1, largest) for _ in range(n_numbers)]\n",
    "        out_pattern = sum(in_pattern)\n",
    "        \n",
    "        X.append(in_pattern)\n",
    "        y.append(out_pattern)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 10], [2, 5]] [13, 7]\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "n_samples = 2\n",
    "n_numbers = 2\n",
    "largest = 10\n",
    "\n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Integers to Padded Strings **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad and convert data to strings\n",
    "def to_string(X, y, n_numbers, largest):\n",
    "    max_length = int(n_numbers * np.ceil(np.log10(largest+1)) + n_numbers - 1)\n",
    "    Xstr = []\n",
    "    for pattern in X:\n",
    "        strp = '+'.join([str(n) for n in pattern])\n",
    "        strp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp\n",
    "        Xstr.append(strp)\n",
    "    \n",
    "    max_length = int(np.ceil(np.log10(n_numbers * (largest + 1))))\n",
    "    ystr = []\n",
    "    \n",
    "    for pattern in y:\n",
    "        strp = str(pattern)\n",
    "        strp = ''.join([' ' for _ in range(max_length - len(strp))]) + strp\n",
    "        ystr.append(strp)\n",
    "    return Xstr, ystr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 8], [8, 8]] [10, 16]\n",
      "['  2+8', '  8+8'] ['10', '16']\n"
     ]
    }
   ],
   "source": [
    "# generate pairs\n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "print(X, y)\n",
    "# convert to strings\n",
    "X, y = to_string(X, y, n_numbers, largest)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Integer Encoded Sequences **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode strings\n",
    "def integer_encode(X, y, alphabet):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    Xenc = []\n",
    "    for pattern in X:\n",
    "        integer_encoded = [char_to_int[char] for char in pattern]\n",
    "        Xenc.append(integer_encoded)\n",
    "    \n",
    "    yenc = []\n",
    "    for pattern in y:\n",
    "        integer_encoded = [char_to_int[char] for char in pattern]\n",
    "        yenc.append(integer_encoded)\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7, 4], [2, 8]] [11, 10]\n",
      "['  7+4', '  2+8'] ['11', '10']\n",
      "[[10, 10, 6, 11, 3], [10, 10, 1, 11, 7]] [[0, 0], [0, 9]]\n"
     ]
    }
   ],
   "source": [
    "# generate pairs\n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "print(X, y)\n",
    "X, y = to_string(X, y, n_numbers, largest)\n",
    "print(X, y)\n",
    "\n",
    "# integer encode\n",
    "alphabet = list('1234567890 +')\n",
    "X, y = integer_encode(X, y, alphabet)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** One Hot Encoded Sequences **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_values = np.array(range(len(alphabet))).reshape(-1, 1)\n",
    "encoder = OneHotEncoder(sparse=False).fit(index_values)\n",
    "\n",
    "def one_hot_encode(X, y):\n",
    "    Xenc = np.array([encoder.transform(np.array(vector).reshape(len(vector), 1)) for vector in X])\n",
    "    yenc = np.array([encoder.transform(np.array(vector).reshape(len(vector), 1)) for vector in y])\n",
    "    return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 7], [7, 10]] [8, 17]\n",
      "['  1+7', ' 7+10'] [' 8', '17']\n",
      "[[10, 10, 0, 11, 6], [10, 6, 11, 0, 9]] [[10, 7], [0, 6]]\n",
      "[[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]] [[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# generate pairs\n",
    "X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "print(X, y)\n",
    "X, y = to_string(X, y, n_numbers, largest)\n",
    "print(X, y)\n",
    "\n",
    "# integer encode\n",
    "alphabet = list('1234567890 +')\n",
    "X, y = integer_encode(X, y, alphabet)\n",
    "print(X, y)\n",
    "\n",
    "# one hot encode\n",
    "X, y = one_hot_encode(X, y)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Sequence Generation Pipeline **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate an encoded dataset\n",
    "def generate_data(n_samples, n_numbers, largest, alphabet):\n",
    "    # generate pairs\n",
    "    X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "    # convert to strings\n",
    "    X, y = to_string(X, y, n_numbers, largest)\n",
    "    # integer encode\n",
    "    X, y = integer_encode(X, y, alphabet)\n",
    "    # one hot encode\n",
    "    X, y = one_hot_encode(X, y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Decode Sequences **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inbert encoding\n",
    "def invert(seq, alphabet):\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    strings = ''.join([int_to_char(np.argmax(vector)) for vector in seq])\n",
    "    return strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Define and Compile the Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of math terms\n",
    "n_terms = 3\n",
    "# largest value for any single input digit\n",
    "largest = 10\n",
    "# scope of possible symbols for each input or output time step\n",
    "alphabet = list('0123456789 +')\n",
    "\n",
    "# size of alphabet\n",
    "n_chars = len(alphabet)\n",
    "# length of input sequence\n",
    "n_in_seq_length = int(n_terms * np.ceil(np.log10(largest+1)) + n_terms - 1)\n",
    "# length of encoded output sequence\n",
    "n_out_seq_length = int(np.ceil(np.log10(n_terms * (largest+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 75)                26400     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 2, 75)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 2, 50)             25200     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2, 12)             612       \n",
      "=================================================================\n",
      "Total params: 52,212\n",
      "Trainable params: 52,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(75, input_shape=(n_in_seq_length, n_chars)))\n",
    "model.add(RepeatVector(n_out_seq_length))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Fit the Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "75000/75000 [==============================] - 18s 237us/step - loss: 0.7217 - acc: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4dbfeaef0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit LSTM\n",
    "X, y = generate_data(75000, n_terms, largest, alphabet)\n",
    "model.fit(X, y, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluate the Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.173809, Accuracy: 98.500000\n"
     ]
    }
   ],
   "source": [
    "# evaluate LSTM\n",
    "X, y = generate_data(100, n_terms, largest, alphabet)\n",
    "loss, acc =  model.evaluate(X, y, verbose=0)\n",
    "print('Loss: %f, Accuracy: %f' % (loss, acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Make Predictions with the Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6048c9a14549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#decode input, expected and predicted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0min_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mout_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-53a12fde6b03>\u001b[0m in \u001b[0;36minvert\u001b[0;34m(seq, alphabet)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mint_to_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstrings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_to_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-53a12fde6b03>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mint_to_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mstrings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint_to_char\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "for _ in range(10):\n",
    "    # generate an input_output pair\n",
    "    X, y = generate_data(1, n_terms, largest, alphabet)\n",
    "    # make prediction\n",
    "    yhat =  model.predict(X, verbose=0)\n",
    "    #decode input, expected and predicted\n",
    "    in_seq = invert(X[0], alphabet)\n",
    "    out_seq = invert(y[0], alphabet)\n",
    "    predicted = invert(yhat[0], alphabet)\n",
    "    print('%s = %s  (expect %s)' % (in_seq, predicted, out_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
